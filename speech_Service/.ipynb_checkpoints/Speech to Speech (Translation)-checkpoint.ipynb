{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_key, service_region = \"______\", \"eastus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_speech_to_speech():\n",
    "\n",
    "    # Creates an instance of a speech translation config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "    translation_config = speechsdk.translation.SpeechTranslationConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Sets the synthesis output voice name.\n",
    "    # Replace with the languages of your choice, from list found here: https://aka.ms/speech/tts-languages\n",
    "    speech_config.speech_synthesis_voice_name = \"hi-IN-Kalpana\"\n",
    "\n",
    "    # Creates a speech synthesizer using the configured voice for audio output.\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "    # Sets source and target languages.\n",
    "    # In this example, the service will translate a US English spoken input, to a German language spoken output\n",
    "    # Replace with the languages of your choice, from list found here: https://aka.ms/speech/sttt-languages\n",
    "    fromLanguage = 'en-US'\n",
    "    toLanguage = 'hi'\n",
    "    translation_config.speech_recognition_language = fromLanguage\n",
    "    translation_config.add_target_language(toLanguage)\n",
    "\n",
    "    # Creates a translation recognizer using and audio file as input.\n",
    "    recognizer = speechsdk.translation.TranslationRecognizer(translation_config=translation_config)\n",
    "\n",
    "    # Prepare to handle the synthesized audio data.\n",
    "    def synthesis_callback(evt):\n",
    "        size = len(evt.result.audio)\n",
    "        print('AUDIO SYNTHESIZED: {} byte(s) {}'.format(size, '(COMPLETED)' if size == 0 else ''))\n",
    "\n",
    "    recognizer.synthesizing.connect(synthesis_callback)\n",
    "\n",
    "    # Starts translation, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognized text as well as the translation.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    print(\"Say something...\")\n",
    "    result = recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.TranslatedSpeech:\n",
    "        print(\"RECOGNIZED '{}': {}\".format(fromLanguage, result.text))\n",
    "        print(\"TRANSLATED into {}: {}\".format(toLanguage, result.translations['hi']))\n",
    "\n",
    "        # Synthesizes the received text to speech.\n",
    "        # The synthesized speech is expected to be heard on the speaker with this line executed.\n",
    "        result = speech_synthesizer.speak_text_async(result.translations['hi']).get()\n",
    "\n",
    "    elif result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"RECOGNIZED: {} (text could not be translated)\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"NOMATCH: Speech could not be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        print(\"CANCELED: Reason={}\".format(result.cancellation_details.reason))\n",
    "        if result.cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"CANCELED: ErrorDetails={}\".format(result.cancellation_details.error_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "RECOGNIZED 'en-US': I like to see what languages you can speak.\n",
      "TRANSLATED into hi: मुझे यह देखना पसंद है कि आप कौन सी भाषाएं बोल सकते हैं।\n"
     ]
    }
   ],
   "source": [
    "translate_speech_to_speech()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MULTIPLE LANGUAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "RECOGNIZED 'en-US': Let's remove the language barrier.\n",
      "TRANSLATED into fr: Supprimons la barrière de la langue.\n",
      "TRANSLATED into hi: चलो भाषा बाधा को दूर करते हैं।\n"
     ]
    }
   ],
   "source": [
    "def translate_speech_to_speech():\n",
    "\n",
    "    # Creates an instance of a speech translation config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "    translation_config = speechsdk.translation.SpeechTranslationConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Creates a speech synthesizer using the configured voice for audio output.\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "    # Sets source and target languages.\n",
    "    # In this example, the service will translate a US English spoken input, to French and Indonesian language spoken output\n",
    "    # Replace with the languages of your choice, from list found here: https://aka.ms/speech/sttt-languages\n",
    "    fromLanguage = 'en-US'\n",
    "    translation_config.speech_recognition_language = fromLanguage\n",
    "\n",
    "    # Add more than one language to the collection.\n",
    "    # using the add_target_language() method\n",
    "    translation_config.add_target_language(\"fr\")\n",
    "    translation_config.add_target_language(\"hi\")\n",
    "\n",
    "    # Creates a translation recognizer using and audio file as input.\n",
    "    recognizer = speechsdk.translation.TranslationRecognizer(translation_config=translation_config)\n",
    "\n",
    "    # Starts translation, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognized text as well as the translation.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    print(\"Say something...\")\n",
    "    result = recognizer.recognize_once()\n",
    "\n",
    "# Check the result\n",
    "    if result.reason == speechsdk.ResultReason.TranslatedSpeech:\n",
    "        # Output the text for the recognized speech input\n",
    "        print(\"RECOGNIZED '{}': {}\".format(fromLanguage, result.text))\n",
    "\n",
    "        # Loop through the returned translation results\n",
    "        for key in result.translations:\n",
    "\n",
    "        # Using the Key and Value components of the returned dictionary for the translated results\n",
    "        # The first portion gets the key (language code) while the second gets the Value\n",
    "        # which is the translated text for the language specified\n",
    "        # Output the language and then the translated text\n",
    "            print(\"TRANSLATED into {}: {}\".format(key, result.translations[key]))\n",
    "\n",
    "            # If the language code is 'fr' for French, then use the French voice for Julie\n",
    "            # If you change the languages in the 'AddTargetLanguage' above, ensure you modify this if statement as well\n",
    "            if key == \"fr\":\n",
    "                speech_config.speech_synthesis_voice_name = \"fr-FR-Julie-Apollo\"\n",
    "\n",
    "                # Update the speech synthesizer to use the proper voice\n",
    "                speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "                # Use the proper voice, from the speech synthesizer configuration, to narrate the translated result\n",
    "                # in the native speaker voice.\n",
    "                speech_synthesizer.speak_text_async(result.translations[key]).get()\n",
    "            else: # Otherwise, use the voice for the Indonesian translation\n",
    "                speech_config.speech_synthesis_voice_name = \"hi-IN-Hemant\"\n",
    "\n",
    "                # Update the speech synthesizer to use the proper voice\n",
    "                speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "                # Use the proper voice, from the speech synthesizer configuration, to narrate the translated result\n",
    "                # in the native speaker voice.\n",
    "                speech_synthesizer.speak_text_async(result.translations[key]).get()\n",
    "\n",
    "    elif result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"RECOGNIZED: {} (text could not be translated)\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"NOMATCH: Speech could not be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        print(\"CANCELED: Reason={}\".format(result.cancellation_details.reason))\n",
    "        if result.cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"CANCELED: ErrorDetails={}\".format(result.cancellation_details.error_details))\n",
    "\n",
    "translate_speech_to_speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
